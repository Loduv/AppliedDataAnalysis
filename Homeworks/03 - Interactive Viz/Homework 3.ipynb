{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import folium\n",
    "\n",
    "# data paths\n",
    "TASK_1_DATA_PATH = './data/lfsa_urgan_1_Data.csv'\n",
    "TASK_2_DATA_PATH = './data/Arbeitslosenquoten_task_2_1.csv'\n",
    "TASK_2_2_DATA_PATH = './data/TASK_2_demandeurs_emploi.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: European unemployment rate (Eurostat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data from [Eurostat](http://ec.europa.eu/eurostat/data/database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database by themes/Population and social conditions/Labour market (Labour)/Employment and Unemployment(Labour Force survey)(employ)/LFS series - detailed annual survey results (LFSA)/ Total unemployment - LFS series(lfsa_unemp)/  Unemployment rates by sex, age and nationality (%) (lfsa_urgan)\n",
    "\n",
    "\n",
    "\n",
    "Age from 15 to 74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we got the data:\n",
    "- we used the data explorer, then 'Download' button, 'Change Selection' to keep only what we're interested in, then download data in CSV format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data importing and cleaning\n",
    "First, we import the unemployement rates from the Eurostat website in a dataframe. Since we are looking for recent statistics, we only keep the data from last year (2016). We also discard all columns except the ones we need (Country and unemployment rate). A few countries also need to be renamed, so that the countries' names are consistent between the eurostat DataFrame and the topojson file. We also drop some unwanted rows, such as the average rate for countries from the European Union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TASK_1_DATA_PATH)\n",
    "df = df[df['TIME']==2016] # only keep data from last year\n",
    "df = df[['GEO', 'Value']] # The only information we need is the country and the unemployment rate\n",
    "df.rename(columns={'GEO': 'Country', 'Value' : 'Unemployment rate' }, inplace=True)\n",
    "df.index = (range(len(df))) # re-index the dataframe\n",
    "\n",
    "# drop unwanted rows, rename some countries to match with the topojson data\n",
    "df = df.replace(to_replace='Former Yugoslav Republic of Macedonia, the', value='The former Yugoslav Republic of Macedonia')\n",
    "df = df.replace(to_replace='Germany (until 1990 former territory of the FRG)', value='Germany')\n",
    "df = df.drop(index=[0,1, 2, 3, 4, 5])\n",
    "\n",
    "df.index = (range(len(df))) # re-index the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we import the topojson data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_geo_path = r'topojson/europe.topojson.json'\n",
    "geo_json_data = json.load(open(state_geo_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see if we are missing some data. To do this, we extract the list of countries from the topojson file and check if some of these countries are not in our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, extract the list of countries from the topojson\n",
    "countries = [country['properties']['NAME'] for country in geo_json_data['objects']['europe']['geometries']]\n",
    "# From this list, print each country that does not appear in the DataFrame\n",
    "missing_countries = set(countries).difference(set(df.Country.values))\n",
    "print(\"The data is missing for %d out of %d countries:\\n\" %(len((missing_countries)), len(countries)))\n",
    "print('\\n'.join(missing_countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ensure that each countries from the DataFrame has been matched to a country in the topojson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(not set(df.Country.values).difference(set(countries)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we don't have the unemployment rate of some countries in topojson file, we need to delete them such that our choropleth plot does not get spoiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_to_keep = [country['properties']['NAME'] in df.Country.values \n",
    "                for country in geo_json_data['objects']['europe']['geometries']]\n",
    "geo_json_data['objects']['europe']['geometries'] = np.array(geo_json_data['objects']['europe']['geometries'])[index_to_keep].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the choropleth map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map([53, 15],  tiles='cartodbpositron', zoom_start=4)\n",
    "#ignore_missing_countries = lambda x: {'fillOpacity':1,'fillColor':'YlOrRd' if x['properties']['NAME'] in df.Country.values else 'black'}\n",
    "#folium.TopoJson(open(state_geo_path), 'objects.europe', style_function =ignore_missing_countries).add_to(m)\n",
    "m.choropleth(\n",
    "    geo_data=geo_json_data,\n",
    "    name='choropleth',\n",
    "    data=df,\n",
    "    columns=['Country', 'Unemployment rate'],\n",
    "    key_on='feature.properties.NAME',\n",
    "    topojson='objects.europe',\n",
    "    fill_color='YlOrRd',\n",
    "    fill_opacity=0.6,\n",
    "    line_opacity=1,\n",
    "    legend_name='Unemployment Rate (%)'\n",
    ")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame('http://localhost:8888/notebooks/ADA_HW/AppliedDataAnalysis/Homeworks/03%20-%20Interactive%20Viz/europe_unemployment_rate.html', width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Unemployment rate in Switzerland\n",
    "this dataframe holds the information from september 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_amstat_dataframe(df):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ch = pd.read_csv(TASK_2_DATA_PATH)\n",
    "\n",
    "# drop unwanted columns\n",
    "cols_to_drop = [i for i in range(1, len(df_ch.columns), 2)]\n",
    "cols_to_drop.append(20)\n",
    "cols_to_drop.append(22)\n",
    "df_ch.drop(df_ch.columns[cols_to_drop],axis=1, inplace=True)\n",
    "\n",
    "#drop unwanted row\n",
    "df_ch.drop(index=[0, len(df_ch)-1], axis=0, inplace=True)\n",
    "\n",
    "# set cantons as index\n",
    "df_ch.set_index('Kanton', drop=True, inplace=True)\n",
    "\n",
    "# cast dataframe values as float\n",
    "df_ch=df_ch.astype(float)\n",
    "\n",
    "# compute the average unemployment rate for each canton\n",
    "df_ch['unemployment rate'] = df_ch.mean(axis=1)\n",
    "df_ch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topo_ch = r'topojson/ch-cantons.topojson.json'\n",
    "topo_ch_data = json.load(open(topo_ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, extract the list of cantons from the topojson\n",
    "cantons_topo = [canton['properties']['name'] for canton in topo_ch_data['objects']['cantons']['geometries']]\n",
    "# From this list, print each canton that does not appear in the DataFrame\n",
    "missing_cantons = set(cantons_topo).difference(set(df_ch.index.values))\n",
    "print(\"Some names are not matching %d / %d\" %(len(missing_cantons), len(cantons_topo)))\n",
    "print('\\n'.join(missing_cantons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace a few names for the cantons whose names are not matching between topojson and dataframe\n",
    "df_ch = df_ch.rename(index={'Genf':'Genève', 'Waadt':'Vaud', 'Neuenburg':'Neuchâtel', 'Graubünden':'Graubünden/Grigioni', 'Tessin':'Ticino', 'Bern':'Bern/Berne', 'Wallis':'Valais/Wallis','Freiburg':'Fribourg'})\n",
    "\n",
    "# assert that every name is matching\n",
    "assert(set(cantons_topo) == set(df_ch.index.values))\n",
    "\n",
    "# we need a 'cantons' column to bind the data with folium\n",
    "df_ch['cantons'] = df_ch.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_ch = folium.Map([46.9, 8.2],  tiles='cartodbpositron', zoom_start=8)\n",
    "map_ch.choropleth(\n",
    "    geo_data=topo_ch_data,\n",
    "    name='choropleth',\n",
    "    data=df_ch,\n",
    "    columns=['cantons', 'unemployment rate'],\n",
    "    key_on='feature.properties.name',\n",
    "    topojson='objects.cantons',\n",
    "    fill_color='YlOrRd',\n",
    "    fill_opacity=0.6,\n",
    "    line_opacity=1,\n",
    "    legend_name='Unemployment Rate (%)'\n",
    ")\n",
    "map_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch2 = pd.read_csv(TASK_2_2_DATA_PATH)\n",
    "\n",
    "\n",
    "# set cantons as index\n",
    "df_ch2.set_index('Kanton', drop=True, inplace=True)\n",
    "\n",
    "# drop unwanted columns\n",
    "cols_to_drop = [i for i in range(len(df_ch2.columns)-6, len(df_ch2.columns))]\n",
    "cols_to_drop.append(0)\n",
    "df_ch2.drop(df_ch2.columns[cols_to_drop],axis=1, inplace=True)\n",
    "df_ch2 = df_ch2.replace({\"'\":\"\"}, regex = True)\n",
    "df_ch2.iloc[1:len(df_ch2.columns)-1] = df_ch2.iloc[1:len(df_ch2.columns)-1].astype(float)\n",
    "#result= []\n",
    "#result.astype(object)\n",
    "\n",
    "#for each month, compute the percentage of unemployed people, excluding those that already have a job but are looking for a new one\n",
    "for i in range(0, len(df_ch2.columns), 3):\n",
    "    ratio = df_ch2.iloc[1:len(df_ch2.columns)-1,i]\n",
    "    total_unemployed = df_ch2.iloc[1:len(df_ch2.columns)-1,i+1]\n",
    "    total_looking = df_ch2.iloc[1:len(df_ch2.columns)-1,i+2]\n",
    "    #result[i] = (ratio/total_unemployed)*(total_unemployed-total_looking)\n",
    "    \n",
    "    \n",
    "\n",
    "'''\n",
    "# drop unwanted columns\n",
    "cols_to_drop = [i for i in range(1, len(df_ch2.columns), 2)]\n",
    "cols_to_drop.append(20)\n",
    "cols_to_drop.append(22)\n",
    "df_ch2.drop(df_ch2.columns[cols_to_drop],axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#drop unwanted row\n",
    "df_ch2.drop(index=[0, len(df_ch)-1], axis=0, inplace=True)\n",
    "\n",
    "# cast dataframe values as float\n",
    "df_ch2=df_ch2.astype(float)\n",
    "\n",
    "# compute the average unemployment rate for each canton\n",
    "df_ch2['unemployment rate'] = df_ch2.mean(axis=1)\n",
    "df_ch2.head()\n",
    "'''\n",
    "\n",
    "df_ch2\n",
    "#result[i-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
