{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "COLOR_TREAT = \"#2ecc71\"\n",
    "COLOR_NO_TREAT = \"#e74c3c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde = pd.read_csv('lalonde.csv')\n",
    "#lalonde.set_index('id', drop=True, inplace=True)\n",
    "lalonde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Naive analysis\n",
    "\n",
    "TODO make a plot more comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "bins = np.histogram(lalonde.re78[lalonde['treat'] == 0])[1]\n",
    "sns.distplot(lalonde.re78[lalonde['treat'] == 0], kde=False, color=COLOR_NO_TREAT, norm_hist=True, bins=bins)\n",
    "sns.distplot(lalonde.re78[lalonde['treat'] == 1], kde=False, color=COLOR_TREAT, norm_hist=True, bins=bins)\n",
    "\n",
    "plt.title('Distribution of the revenues')\n",
    "plt.xlabel('Revenue in 1978')\n",
    "plt.ylabel('Number of persons (Density)')\n",
    "plt.legend(['No treatment', 'Treatment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the average earnings of people that have/have not participated the job training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(121)\n",
    "plt.title('Mean salary with/without training')\n",
    "plt.ylabel('Mean salaray')\n",
    "lalonde.groupby(['treat'])['re78'].mean().plot.bar(color=[COLOR_NO_TREAT, COLOR_TREAT])\n",
    "plt.subplot(122)\n",
    "plt.title('Median salary with/without training')\n",
    "plt.ylabel('Median Salary')\n",
    "lalonde.groupby(['treat'])['re78'].median().plot.bar(color=[COLOR_NO_TREAT, COLOR_TREAT])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A closer look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinguish categorical from non-categorical features\n",
    "sns.set(font_scale=1.2)\n",
    "lalonde_cat = lalonde[['black', 'hispan', 'married', 'nodegree', 'treat']]\n",
    "lalonde_non_cat = lalonde[['age', 'educ', 're74', 're75', 're78', 'treat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each feature, compare its distribution in the treated group with its distribution in the control group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(3, 3, figsize=(15, 18))\n",
    "for index, feature in enumerate(['age', 'educ', 'black', 'hispan', 'married', 'nodegree', 're74', 're75', 're78']):\n",
    "    i = int(index/3)\n",
    "    j = index%3\n",
    "    bins = np.histogram(lalonde[feature][lalonde['treat'] == 0])[1]\n",
    "    sns.distplot(lalonde[feature][lalonde['treat'] == 0], kde=False, color=COLOR_NO_TREAT, norm_hist=True, ax=axarr[i][j], bins=bins)\n",
    "    sns.distplot(lalonde[feature][lalonde['treat'] == 1], kde=False, color=COLOR_TREAT, norm_hist=True, ax=axarr[i][j], bins=bins)\n",
    "    axarr[i][j].set_title(feature)\n",
    "    axarr[i][j].set_xlabel(feature)\n",
    "    axarr[i][j].set_ylabel('Density')\n",
    "    axarr[i][j].legend(['No treatment', 'Treatment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise analysis of features' distribution\n",
    "Comparing the distrbution of features for each distinct feature tuple can give additional information:\n",
    "**TODO : d√©crire les obs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(lalonde_non_cat, hue='treat', palette={0:\"#e74c3c\", 1: \"#2ecc71\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A propsensity score model\n",
    "We should fit our model on the pre treatment features, though we will have to remove the re78 feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "\n",
    "lal = lalonde.drop(['id','treat','re78'],1)\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(lal, lalonde.treat)\n",
    "pred = model.predict_proba(lal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde['pred'] = pred[:,1]\n",
    "ax = sns.stripplot(x='id', y='pred', hue='treat', data=lalonde, palette={0:\"#e74c3c\", 1: \"#2ecc71\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Balancing the dataset via matching\n",
    "Use the propensity scores to match each data point from the treated group with exactly one data point from the control group, while ensuring that each data point from the control group is matched with at most one data point from the treated group. (Hint: you may explore the networkx package in Python for predefined matching functions.)\n",
    "\n",
    "Your matching should maximize the similarity between matched subjects, as captured by their propensity scores. In other words, the sum (over all matched pairs) of absolute propensity-score differences between the two matched subjects should be minimized.\n",
    "\n",
    "After matching, you have as many treated as you have control subjects. Compare the outcomes (re78) between the two groups (treated and control).\n",
    "\n",
    "Also, compare again the feature-value distributions between the two groups, as you've done in part 2 above, but now only for the matched subjects. What do you observe? Are you closer to being able to draw valid conclusions now than you were before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "#graph_size = lalonde['treat'].value_counts()\n",
    "#G = nx.complete_bipartite_graph(graph_size[0], graph_size[1])\n",
    "#G.add_nodes_from(lalonde['id'][lalonde.treat == 0], bipartite=0) # Add the node attribute \"bipartite\"\n",
    "#G.add_nodes_from(lalonde['id'][lalonde.treat == 1], bipartite=1)\n",
    "\n",
    "G=nx.Graph()\n",
    "G.add_nodes_from(lalonde['id'][lalonde.treat == 0]) # Add the node attribute \"bipartite\"\n",
    "G.add_nodes_from(lalonde['id'][lalonde.treat == 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ID_u, score_u in zip(lalonde.id[lalonde.treat == 0], lalonde.pred[lalonde.treat == 0]):\n",
    "    for ID_v, score_v in zip(lalonde.id[lalonde.treat == 1], lalonde.pred[lalonde.treat == 1]):\n",
    "        G.add_edge(ID_u, ID_v, weight=-abs(score_u-score_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_nodes()\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import max_weight_matching\n",
    "matching = max_weight_matching(G, maxcardinality=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Balancing the groups further\n",
    "The \"balanced\" mode uses the values of y to automatically adjust\n",
    "    weights inversely proportional to class frequencies in the input data\n",
    "    as ``n_samples / (n_classes * np.bincount(y))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. A less naive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
