{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "COLOR_TREAT = \"#2ecc71\"\n",
    "COLOR_NO_TREAT = \"#e74c3c\"\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Propensity score matching\n",
    "\n",
    "We will work with a dataset from Robert LaLonde's study Evaluating the Econometric Evaluations of Training Programs.\n",
    "\n",
    "The study investigated the effect of a job training program (\"National Supported Work Demonstration\") on the real earnings of an individual, a couple of years after completion of the program.\n",
    "Our task is to determine the effectiveness of the \"treatment\" represented by the job training program.\n",
    "\n",
    "The features of this dataset are:\n",
    "\n",
    "- `treat`: 1 if the subject participated in the job training program, 0 otherwise\n",
    "- `age`: the subject's age\n",
    "- `educ`: years of education\n",
    "- `race`: categorical variable with three possible values: Black, Hispanic, or White\n",
    "- `married`: 1 if the subject was married at the time of the training program, 0 otherwise\n",
    "- `nodegree`: 1 if the subject has earned no school degree, 0 otherwise\n",
    "- `re74`: real earnings in 1974 (pre-treatment)\n",
    "- `re75`: real earnings in 1975 (pre-treatment)\n",
    "- `re78`: real earnings in 1978 (outcome)\n",
    "\n",
    "\n",
    "First let's import and have a look to the data :\n",
    "\n",
    "Note that the `race` variable is changed to `black` and `hispan`. Therefore someone with `black=0` and `hispan=0` is White."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's import the dataset and observe the first rows\n",
    "lalonde = pd.read_csv('lalonde.csv')\n",
    "lalonde.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Naive analysis\n",
    "\n",
    "Compare the distribution of the outcome variable (`re78`) between the two groups, using plots and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We define this function to have clean distribution plot as we are going to use them a lot through our analysis\n",
    "def plot_distrib(s1, s2, title, xLabel, yLabel, ax=None):\n",
    "    bins = np.histogram(s1)[1]\n",
    "    sns.distplot(s1, kde=False, color=COLOR_NO_TREAT, norm_hist=True, ax=ax, bins=bins)\n",
    "    sns.distplot(s2, kde=False, color=COLOR_TREAT, norm_hist=True, ax=ax, bins=bins)\n",
    "    if ax is None:\n",
    "        plt.title(title)\n",
    "        plt.xlabel(xLabel)\n",
    "        plt.ylabel(yLabel)\n",
    "        plt.legend(['No treatment', 'Treatment'])\n",
    "    else:\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(xLabel)\n",
    "        ax.set_ylabel(yLabel)\n",
    "        ax.legend(['No treatment', 'Treatment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's compare the two distributions. The distribution in red is the distribution of the revenues in 78 for the people that didn't take part in the job training program (no treatment), whereas the one in green is the distribution of the revenues in 78 for the people that took part in the job training program (treatment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot the two distributions\n",
    "plt.figure(figsize=(12,5))\n",
    "plot_distrib(s1=lalonde.re78[lalonde['treat'] == 0], s2=lalonde.re78[lalonde['treat'] == 1], title='Distribution of the revenues', ax=None, xLabel='Revenue in 1978', yLabel='Number of persons (Density)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that people that didn't take part in the training programs seem to have better earnings. Indeed, the histogram shows that the green bars are higher than the red ones for the small revenues whereas the red ones are higher for the higher revenues.\n",
    "\n",
    "TODO : PEUT ETRE FAIRE UN KOLMO SMIRNORFF TEST ICI POUR MONTRER QUE LES DISTRIB SONT BIEN DIFFERENTES.\n",
    "\n",
    "Now, let's compare other indicators for the people that have/have not participated the job training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lalonde['diff'] = lalonde['re78'] - lalonde['re75']\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "axes = plt.subplot(131)\n",
    "lalonde.groupby(['treat'])['re78'].mean().plot.bar(color=[COLOR_NO_TREAT, COLOR_TREAT])\n",
    "plt.title('Mean salary with/without training')\n",
    "plt.ylabel('Mean salaray')\n",
    "plt.xlabel('Traning')\n",
    "plt.subplot(132)\n",
    "lalonde.groupby(['treat'])['re78'].median().plot.bar(color=[COLOR_NO_TREAT, COLOR_TREAT])\n",
    "plt.title('Median salary with/without training')\n",
    "plt.ylabel('Median Salary')\n",
    "plt.xlabel('Training')\n",
    "plt.subplot(133)\n",
    "lalonde.groupby(['treat'])['diff'].mean().plot.bar(color=[COLOR_NO_TREAT, COLOR_TREAT])\n",
    "plt.title('Difference of salary between 78 and 75 with/without training')\n",
    "plt.ylabel('Difference of Salary')\n",
    "plt.xlabel('Training')\n",
    "\n",
    "lalonde = lalonde.drop('diff',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we first compare the mean and the median of the revenues in 78 for the two groups. We notice that both of these indicators are higher for the people that didn't have the training. \n",
    "\n",
    "We thought that another interesting indicator would be to compare the difference of earnings between 78 and 75 for both groups. We observe on the plot that the training program helped a bit, but the difference is very small.\n",
    "\n",
    "Therefore the naive approach concludes that the training program is not effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A closer look at the data\n",
    "\n",
    "For each feature in the dataset, compare its distribution in the treated group with its distribution in the control group, using plots and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# distinguish categorical from non-categorical features\n",
    "sns.set(font_scale=1.2)\n",
    "lalonde_cat = lalonde[['black', 'hispan', 'married', 'nodegree', 'treat']]\n",
    "lalonde_non_cat = lalonde[['age', 'educ', 're74', 're75', 're78', 'treat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(3, 3, figsize=(15, 18))\n",
    "for index, feature in enumerate(['age', 'educ', 'black', 'hispan', 'married', 'nodegree', 're74', 're75', 're78']):\n",
    "    ax = axarr[int(index/3)][index%3]\n",
    "    plot_distrib(s1=lalonde[feature][lalonde['treat'] == 0], s2=lalonde[feature][lalonde['treat'] == 1], title=feature, xLabel = feature, yLabel='Density', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the distributions plotted. If we want our analysis not to be naive, these distributions should be almost the same along the two categories (treated and not treated).\n",
    "\n",
    "We can already spot some huge differences from these plots (Features Black and Married for example) but some Kolmogorov–Smirnov 2 sample tests will help us be sure of our analysis.\n",
    "\n",
    "The Kolmogorov–Smirnov 2 sample tests whether 2 samples are drawn from the same distribution. If the K-S statistic is small or the p-value is high, then we cannot reject the hypothesis that the distributions of the two samples are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\\\n') \n",
    "for feature in ['age', 'educ', 'black', 'hispan', 'married', 'nodegree', 're74', 're75', 're78']: \n",
    "    ks = stats.ks_2samp(lalonde[feature][lalonde['treat'] == 0], lalonde[feature][lalonde['treat'] == 1]) \n",
    "    print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a threshold of 0.05 for the p-value. We can therefore reject the null hypothesis for the following features :\n",
    "\n",
    "- Age\n",
    "- Black\n",
    "- Married\n",
    "- re74\n",
    "- re75\n",
    "\n",
    "As seen in class, a propensity score matching can help us equilibrate these distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise analysis of features' distribution\n",
    "Comparing the distrbution of features for each distinct feature tuple can give additional information:\n",
    "**TODO : décrire les obs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(lalonde_non_cat, hue='treat', palette={0:\"#e74c3c\", 1: \"#2ecc71\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A propsensity score model\n",
    "\n",
    "We should fit our model on the pre treatment features, though we will have to remove the re78 feature.\n",
    "Furthermore, we preprocess our data by standardizing them so we don't have some features that have more importance than some others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "#removing the useless features\n",
    "lal = lalonde.drop(['id','treat','re78'],1)\n",
    "#Standardize the dataset\n",
    "lal = preprocessing.scale(lal)\n",
    "#Perform a logistic regression in order to get the propensity score for each individuals\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(lal, lalonde.treat)\n",
    "pred = model.predict_proba(lal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check the performance of our model, we have an accuracy of 82%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(model.predict(lal) == lalonde.treat)/len(lal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "lalonde['pred'] = pred[:,1]\n",
    "ax = sns.stripplot(x='id', y='pred', hue='treat', data=lalonde, palette={0:\"#e74c3c\", 1: \"#2ecc71\"})\n",
    "ax.set(xticklabels=[], ylabel='Treatment (prediction)')\n",
    "plt.title('Propensity score per induvidual')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., handles=ax.get_legend_handles_labels()[0], labels=['Without', 'With'], title='Treatment (ground truth)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows us what is the propensity score for each individuals. \n",
    "The individuals that received the treatment are in green and should have a score around 1 whereas the individuals that didn't receive it are in red and should have a score around 0.\n",
    "\n",
    "Even if we have some outliers, this is the case.\n",
    "\n",
    "## 4. Balancing the dataset via matching\n",
    "Use the propensity scores to match each data point from the treated group with exactly one data point from the control group, while ensuring that each data point from the control group is matched with at most one data point from the treated group.\n",
    "\n",
    "In order to do this matching, we will procede in the following way:\n",
    "\n",
    "- First we will create a bipartite graph where the first part is composed of people who received the training and the second part is composed of people who did not receive the training.\n",
    "\n",
    "- Then we will make this bipartite graph complete. It means that the vertices are partitioned into two subsets V1 (the people who received the training) and V2 (the people who did not receive the traing) such that no edge has both endpoints in the same subset, and every possible edge that could connect vertices in different subsets is part of the graph. This way will will be sure to match people with treatment with people without treatmant\n",
    "\n",
    "- We will give a weight to these edges: Let's take two individuals,we denote by $w_1$ the propensity score of the treated individual and $w_2$ the propensity score of the untreated individual. The weight of the edge between them will be:\n",
    "$$W = - |w_{1} - w_{2}| $$\n",
    "\n",
    "- Finally we will use a maximum weight matching with max cardinality algorithm. Note that we have a minus sign in our weights because we want to minimize the weights even though we are using a maximum weight matching algorithm. We are using the method implemented in the NetworkX package. This method is based on the “blossom” method for finding augmenting paths and the “primal-dual” method for finding a matching of maximum weight, you can read more about it there : https://dl.acm.org/citation.cfm?id=6502 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "#graph_size = lalonde['treat'].value_counts()\n",
    "#G = nx.complete_bipartite_graph(graph_size[0], graph_size[1])\n",
    "#G.add_nodes_from(lalonde['id'][lalonde.treat == 0], bipartite=0) # Add the node attribute \"bipartite\"\n",
    "#G.add_nodes_from(lalonde['id'][lalonde.treat == 1], bipartite=1)\n",
    "\n",
    "G=nx.Graph()\n",
    "G.add_nodes_from(lalonde['id'][lalonde.treat == 0]) # Add the node attribute \"bipartite\"\n",
    "G.add_nodes_from(lalonde['id'][lalonde.treat == 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ID_u, score_u in zip(lalonde.id[lalonde.treat == 0], lalonde.pred[lalonde.treat == 0]):\n",
    "    for ID_v, score_v in zip(lalonde.id[lalonde.treat == 1], lalonde.pred[lalonde.treat == 1]):\n",
    "        G.add_edge(ID_u, ID_v, weight=-abs(score_u-score_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.number_of_nodes()\n",
    "G.number_of_edges()\n",
    "#nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from networkx.algorithms import max_weight_matching\n",
    "matching = max_weight_matching(G, maxcardinality=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dict()\n",
    "for key in matching.keys():\n",
    "    if(key[0] == 'N'):\n",
    "        res[key] = matching[key]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde_treated = lalonde[lalonde['treat'] == 1]\n",
    "lalonde_treated['temp'] = 1\n",
    "#lalonde_treated\n",
    "\n",
    "lalonde_nt = lalonde[lalonde['treat'] == 0]\n",
    "lalonde_nt['temp'] = 1\n",
    "#lalonde_nt\n",
    "\n",
    "result = pd.merge(lalonde_treated, lalonde_nt, on='temp')\n",
    "result = result[['id_x' , 'id_y' , 'pred_x' , 'pred_y']]\n",
    "result['diff'] = abs(result['pred_x'] - result['pred_y'])\n",
    "result = result.set_index(['id_x', 'id_y'])\n",
    "sum(result.loc[list(res.items())]['diff'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[list(res.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lalondeid = lalonde.set_index('id')\n",
    "matched = lalondeid.loc[list(matching.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_distrib(s1=matched.re78[matched['treat'] == 0], s2=matched.re78[matched['treat'] == 1], \n",
    "             title='Distribution of the revenues', ax=None, xLabel='Revenue in 1978', yLabel='Number of persons (Density)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched['diff'] = matched['re78'] - matched['re75']\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(131)\n",
    "plt.title('Mean salary with/without training')\n",
    "plt.ylabel('Mean salaray')\n",
    "matched.groupby(['treat'])['re78'].mean().plot.bar(color=[COLOR_NO_TREAT, COLOR_TREAT])\n",
    "plt.subplot(132)\n",
    "plt.title('Median salary with/without training')\n",
    "plt.ylabel('Median Salary')\n",
    "matched.groupby(['treat'])['re78'].median().plot.bar(color=[COLOR_NO_TREAT, COLOR_TREAT])\n",
    "plt.subplot(133)\n",
    "matched.groupby(['treat'])['diff'].mean().plot.bar(color=[COLOR_NO_TREAT, COLOR_TREAT])\n",
    "plt.title('Difference of salary between 78 and 75 with/without training')\n",
    "plt.ylabel('Difference of Salary')\n",
    "plt.xlabel('Training')\n",
    "\n",
    "matched = matched.drop('diff',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(3, 3, figsize=(15, 18))\n",
    "for index, feature in enumerate(['age', 'educ', 'black', 'hispan', 'married', 'nodegree', 're74', 're75', 're78']):\n",
    "    ax = axarr[int(index/3)][index%3]\n",
    "    plot_distrib(s1=matched[feature][matched['treat'] == 0], s2=matched[feature][matched['treat'] == 1], title=feature, xLabel = feature, yLabel='Density', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import stats\n",
    "\n",
    "\n",
    "#for feature in ['age', 'educ', 'black', 'hispan', 'married', 'nodegree', 're74', 're75', 're78']:\n",
    "    #ks = stats.ks_2samp(matched[feature][matched['treat'] == 0], matched[feature][matched['treat'] == 1])\n",
    "    #print('For ' + str(feature)+ ' the KS stat and P-values are ' +str(ks))\n",
    "    \n",
    "from scipy import stats \n",
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\\\n') \n",
    "for feature in ['age', 'educ', 'black', 'hispan', 'married', 'nodegree', 're74', 're75', 're78']: \n",
    "    ks = stats.ks_2samp(matched[feature][matched['treat'] == 0], matched[feature][matched['treat'] == 1]) \n",
    "    print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Balancing the groups further\n",
    "The \"balanced\" mode uses the values of y to automatically adjust\n",
    "    weights inversely proportional to class frequencies in the input data\n",
    "    as ``n_samples / (n_classes * np.bincount(y))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lalonde = pd.read_csv('lalonde.csv')\n",
    "#lal = lalonde.drop(['id','treat','re78'],1)\n",
    "#lal = preprocessing.scale(lal)\n",
    "#model = sklearn.linear_model.LogisticRegression()\n",
    "#model.fit(lal, lalonde.treat)\n",
    "#pred = model.predict_proba(lal)\n",
    "#lalonde['pred'] = pred[:,1]\n",
    "\n",
    "\n",
    "Gprime=nx.Graph()\n",
    "Gprime.add_nodes_from(lalonde['id'][lalonde.treat == 0])\n",
    "Gprime.add_nodes_from(lalonde['id'][lalonde.treat == 1])\n",
    "\n",
    "lalonde_not_black = lalonde[lalonde.black == 0]\n",
    "for ID_u, score_u in zip(lalonde_not_black.id[lalonde_not_black.treat == 0], lalonde_not_black.pred[lalonde_not_black.treat == 0]):\n",
    "    for ID_v, score_v in zip(lalonde_not_black.id[lalonde_not_black.treat == 1], lalonde_not_black.pred[lalonde_not_black.treat == 1]):\n",
    "        Gprime.add_edge(ID_u, ID_v, weight=-abs(score_u-score_v))\n",
    "\n",
    "lalonde_black = lalonde[lalonde.black == 1]\n",
    "for ID_u, score_u in zip(lalonde_black.id[lalonde_black.treat == 0], lalonde_black.pred[lalonde_black.treat == 0]):\n",
    "    for ID_v, score_v in zip(lalonde_black.id[lalonde_black.treat == 1], lalonde_black.pred[lalonde_black.treat == 1]):\n",
    "        Gprime.add_edge(ID_u, ID_v, weight=-abs(score_u-score_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matching = max_weight_matching(Gprime, maxcardinality=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lalonde.set_index('id' , inplace = True)\n",
    "matched = lalonde.loc[list(matching.keys())]\n",
    "matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(3, 3, figsize=(15, 18))\n",
    "for index, feature in enumerate(['age', 'educ', 'black', 'hispan', 'married', 'nodegree', 're74', 're75', 're78']):\n",
    "    ax = axarr[int(index/3)][index%3]\n",
    "    plot_distrib(s1=matched[feature][matched['treat'] == 0], s2=matched[feature][matched['treat'] == 1], title=feature, xLabel = feature, yLabel='Density', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "print(('feature').ljust(10), ('statistic').ljust(10), ('p value').ljust(0), '\\n')\n",
    "for feature in ['age', 'educ', 'black', 'hispan', 'married', 'nodegree', 're74', 're75', 're78']:\n",
    "    ks = stats.ks_2samp(matched[feature][matched['treat'] == 0], matched[feature][matched['treat'] == 1])\n",
    "    print(feature.ljust(10), '%.3f'.ljust(10) %ks[0], '%.3f'.ljust(0) %ks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. A less naive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched['diff'] = matched['re78'] - matched['re75']\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(131)\n",
    "plt.title('Mean salary with/without training')\n",
    "plt.ylabel('Mean salaray')\n",
    "matched.groupby(['treat'])['re78'].mean().plot.bar(color=[COLOR_NO_TREAT, COLOR_TREAT])\n",
    "plt.subplot(132)\n",
    "plt.title('Median salary with/without training')\n",
    "plt.ylabel('Median Salary')\n",
    "matched.groupby(['treat'])['re78'].median().plot.bar(color=[COLOR_NO_TREAT, COLOR_TREAT])\n",
    "plt.subplot(133)\n",
    "matched.groupby(['treat'])['diff'].mean().plot.bar(color=[COLOR_NO_TREAT, COLOR_TREAT])\n",
    "plt.title('Difference of salary between 78 and 75 with/without training')\n",
    "plt.ylabel('Difference of Salary')\n",
    "plt.xlabel('Training')\n",
    "\n",
    "matched = matched.drop('diff',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Applied ML\n",
    "We are going to build a classifier of news to directly assign them to 20 news categories. Note that the pipeline that you will build in this exercise could be of great help during your project if you plan to work with text!\n",
    "\n",
    "- Load the 20newsgroup dataset. It is, again, a classic dataset that can directly be loaded using sklearn. TF-IDF, short for term frequency–inverse document frequency, is of great help when if comes to compute textual features. Indeed, it gives more importance to terms that are more specific to the considered articles (TF) but reduces the importance of terms that are very frequent in the entire corpus (IDF). Compute TF-IDF features for every article using TfidfVectorizer. Then, split your dataset into a training, a testing and a validation set (10% for validation and 10% for testing). Each observation should be paired with its corresponding label (the article category).\n",
    "\n",
    "- Train a random forest on your training set. Try to fine-tune the parameters of your predictor on your validation set using a simple grid search on the number of estimator \"n_estimators\" and the max depth of the trees \"max_depth\". Then, display a confusion matrix of your classification pipeline. Lastly, once you assessed your model, inspect the feature_importances_ attribute of your random forest and discuss the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "newsgroups.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the target names inside the newsgroup dataset\n",
    "## 2.1 Load the data, vectorize it and split it into training set and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(newsgroups.data) \n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has 18846 datapoints and 173762 features. Now let split it into train, valid and test set. To do so, we created a function *get_train_valid_test_set* written in the box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_valid_test_set(data, labels, perc_for_valid, perc_for_test):\n",
    "    # returns the train, valid and test sets\n",
    "    # data : n x nb_features matrix\n",
    "    # perc_for_valid : value between 0 and 1 as the percentage of the dataset to be used in validation\n",
    "    # perc_for_test : value between 0 and 1 as the percentage of the dataset to be used in testing\n",
    "    \n",
    "    uindx = np.random.permutation(np.shape(data)[0])\n",
    "    X_shuffled = data[uindx]\n",
    "    labels_shf = labels[uindx]\n",
    "    \n",
    "    # take perc_for_test% of the dataset for testing\n",
    "    X_test_shf = X_shuffled[:int(X_shuffled.shape[0]*perc_for_test)]\n",
    "    y_test_shf = labels_shf[:int(X_shuffled.shape[0]*perc_for_test)]\n",
    "    \n",
    "    # take perc_for_valid% of the dataset for validation\n",
    "    X_valid_shf = X_shuffled[int(X_shuffled.shape[0]*perc_for_test):\n",
    "                             int(X_shuffled.shape[0]*(perc_for_test + perc_for_valid))]\n",
    "    y_valid_shf = labels_shf[int(X_shuffled.shape[0]*perc_for_test):\n",
    "                             int(X_shuffled.shape[0]*(perc_for_test + perc_for_valid))]\n",
    "    \n",
    "    X_train_shf = X_shuffled[int(X_shuffled.shape[0]*(perc_for_test + perc_for_valid)):]\n",
    "    y_train_shf = labels_shf[int(X_shuffled.shape[0]*(perc_for_test + perc_for_valid)):]\n",
    "    \n",
    "    return X_test_shf, X_train_shf, X_valid_shf, y_test_shf, y_train_shf, y_valid_shf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_train, X_valid, y_test, y_train, y_valid = get_train_valid_test_set(X, newsgroups.target, 0.1, 0.1)\n",
    "print('test set size : '+ str(X_test.shape))\n",
    "print('valid set size : '+ str(X_valid.shape))\n",
    "print('train set size : '+ str(X_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Classification\n",
    "**Train a random forest** on your training set. Try to **fine-tune the parameters** of your predictor on your validation set using a simple grid search on the number of estimator \"n_estimators\" and the max depth of the trees \"max_depth\". Then, **display a confusion matrix** of your classification pipeline. Lastly, once you assessed your model, **inspect the feature_importances_** attribute of your random forest and discuss the obtained results.\n",
    "\n",
    "### Fine Tune max depth and number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "number_trees = [125, 300, 500, 600]\n",
    "max_depth = [5, 8, 12, 16, 20]\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "#Loop for hyperparameter number_trees and max_depth\n",
    "for nb_t in number_trees:\n",
    "    for nb_d in max_depth:\n",
    "\n",
    "        # Random forest model\n",
    "        rand_forest_model = RandomForestClassifier(n_estimators=nb_t, max_depth=nb_d)\n",
    "        rand_forest_model.fit(X_train, y_train)\n",
    "        y_pred_val = rand_forest_model.predict(X_valid)\n",
    "\n",
    "        # get score\n",
    "        score = accuracy_score(y_valid, y_pred_val)\n",
    "        #print('loading : '+ str(stepinfo/(len(number_trees)*len(max_depth))) + '% nb_trees : ' + str(nb_t) + ' depth : '\n",
    "        #      + str(nb_d) + ' score : ' + str(score))\n",
    "        \n",
    "        # update best score if needed\n",
    "        if score > best_score:\n",
    "            best_nb_trees = nb_t\n",
    "            best_max_depth = nb_d\n",
    "            best_score = score\n",
    "print(best_score)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_forest_model = RandomForestClassifier(n_estimators=best_nb_trees, max_depth=best_max_depth)\n",
    "rand_forest_model.fit(X_train, y_train)\n",
    "y_pred_test = rand_forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred_test, y_test)\n",
    "#np.fill_diagonal(cm, 0)\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO : regarder comment mettre la confusion matrix en % \n",
    "Faire la features importance\n",
    "Analayser tout ca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(best_nb_trees)\n",
    "print(best_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y_pred_test)\n",
    "sklearn.metrics.accuracy_score(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
