{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = './Data' # Use the data folder provided in Tutorial 02 - Intro to Pandas.\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# ignore annoying warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Compiling Ebola Data\n",
    "\n",
    "The `DATA_FOLDER/ebola` folder contains summarized reports of Ebola cases from three countries (Guinea, Liberia and Sierra Leone) during the recent outbreak of the disease in West Africa. For each country, there are daily reports that contain various information about the outbreak in several cities in each country.\n",
    "\n",
    "Use pandas to import these data files into a single `Dataframe`.\n",
    "Using this `DataFrame`, calculate for *each country*, the *daily average per month* of *new cases* and *deaths*.\n",
    "Make sure you handle all the different expressions for *new cases* and *deaths* that are used in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "\n",
    "### field names\n",
    "- The fields \"National\" in SL and Liberia mean the same as the \"Totals\" field in Guinea, i.e. the Total number of cases in the country.\n",
    "\n",
    "### missing data\n",
    "- When there's a NaN (the value was not filled), we assume that the data was lost, or not written down.\n",
    "- When a report (csv file) for a given day is missing, we assume that nothing happened during this day.\n",
    "- We are only interested in the Totals/National columns. If a row contains a NaN in this column, we chose to discard the row. This should not be problematic (if the number of NaNs in *Totals* is reasonably low), since we consider the daily **average** per month.\n",
    "\n",
    "### fields meaning and aggregation\n",
    "- Since we don't have additionnal information on the data, especially about the meanings of some fields, we decide to compute the new cases separaterly for the confirmed, probable and suspect cases. Same goes for the deaths.\n",
    "    - We also add a column that sums all the new cases/deaths\n",
    "\n",
    "\n",
    "### Used/Discarded fields\n",
    "- We only consider the totals/national fields, not the values per district/region. Sometimes, the sum of the values per region is a bit higher than the total. We assume that's because some smaller regions are not shown in the data.\n",
    "    - For this reason, if the *Totals* value is NaN, we cannot just sum up the values of the different regions.\n",
    "- After observing the data, we can safely assume that the deaths, unlike the new cases, are reported cumulatively. I.e., the number of deaths reported on day *d* is the number of deaths that happened this day, plus all the deaths that happened in the previous days. We did not use the *new deaths* values, because for some countries there is no distinction between the different cases (confirmed, probable and suspected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Process\n",
    "- Importing the data\n",
    "- Merge and clean the full dataset\n",
    "- Unstack Description column\n",
    "- Daily averages computation\n",
    "- Results\n",
    "- Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data from CSVs\n",
    "guinea = []\n",
    "liberia = []\n",
    "sl = []\n",
    "dfs = [guinea, liberia, sl]\n",
    "i = 0\n",
    "folders = [\"guinea_data\", \"liberia_data\", \"sl_data\"]\n",
    "for folder in folders:\n",
    "    path = DATA_FOLDER + \"/ebola/\"\n",
    "    for file in os.listdir(path + folder):\n",
    "        dfs[i].append(pd.read_csv(path + folder + '/' + file))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Guinea data into DataFrame\n",
    "guinea = pd.DataFrame()\n",
    "i = 0\n",
    "for df in dfs[0]:\n",
    "    df['Country'] = 'Guinea' # set the new country column\n",
    "    dfs[0][i] = df\n",
    "    i += 1\n",
    "guinea = pd.concat(dfs[0])\n",
    "guinea.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import liberia data into DataFrame\n",
    "liberia = pd.DataFrame()\n",
    "i = 0\n",
    "for df in dfs[1]:\n",
    "    df['Country'] = 'Liberia'\n",
    "    df = df.rename(columns = {'National':'Totals', 'Variable':'Description'})\n",
    "    dfs[1][i] = df\n",
    "    i += 1\n",
    "liberia = pd.concat(dfs[1])\n",
    "liberia.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Sierra Leone data into DataFrame\n",
    "sl = pd.DataFrame()\n",
    "i = 0\n",
    "for df in dfs[2]:\n",
    "    df['Country'] = 'Sierra Leone'\n",
    "    df = df.rename(columns = {'National':'Totals', 'date' : 'Date', 'variable':'Description'})\n",
    "    dfs[2][i] = df\n",
    "    i += 1\n",
    "sl = pd.concat(dfs[2])\n",
    "sl.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Merge and clean the full dataset (all countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "full_data = pd.concat([guinea, liberia, sl])\n",
    "\n",
    "# remove each row whose 'Totals' value is NaN\n",
    "n_col_before = full_data.shape[0]\n",
    "full_data = full_data[full_data.Totals.notnull()]\n",
    "n_col_after = full_data.shape[0]\n",
    "print(\"Removed \" + str(n_col_before-n_col_after) + \" rows out of \" + str(n_col_before))\n",
    "\n",
    "# Specify that the Date column contains datetime objects\n",
    "full_data.Date = pd.to_datetime(full_data.Date)\n",
    "\n",
    "# To facilitate readability, we discard all the columns we don't need\n",
    "full_data_crop = full_data[['Country', 'Description', 'Totals', 'Date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the dataframe that we'll use to compute the different values looks like so far: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " full_data_crop.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Unstack *Description* column\n",
    "\n",
    "Each distinct value of the *Description* column becomes a new column. In order to do that, we first clean the different *Description* values so that there are consistent across the different countries.\n",
    "\n",
    "For example, in Sierra Leone, The number of confirmed deaths is referred as *death_confirmed*, but as *Total death/s in confirmed cases* in Liberia.\n",
    "\n",
    "Then, since we are only interested in deaths and new cases, we discard all the rows that concern other things.\n",
    "\n",
    "Finally, we noticed when trying to unstack the data that there were three exact duplicate rows from the liberian data. Thus, we removed those rows.\n",
    "\n",
    "We can then finally unstack the descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Names and regexes that we use to process the Description\n",
    "\n",
    "interests_rgx = ['(new_suspected|New cases of suspects|New Case\\/s \\(Suspected\\))',\n",
    "             '(new_probable|New cases of probables|New Case\\/s \\(Probable\\))',\n",
    "             '(new_confirmed|New cases of confirmed|New case\\/s \\(confirmed\\))',\n",
    "             '(death_suspected|Total deaths of suspects|Total death\\/s in suspected cases)',\n",
    "             '(death_probable|Total deaths of probables|Total death\\/s in probable cases)',\n",
    "             '(death_confirmed|Total deaths of confirmed|Total death\\/s in confirmed cases)'\n",
    "            ]\n",
    "\n",
    "interests_new_cases = ['New cases (suspected)', 'New cases (probable)', 'New cases (confirmed)']\n",
    "interests_death = ['Deaths in suspected cases', 'Deaths in probable cases', 'Deaths in confirmed cases']\n",
    "interests_names = interests_new_cases + interests_death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We decided to unstack the Descriptions column in other columns\n",
    "\n",
    "# uniformize description in needed columns\n",
    "for i in range(len(interests_rgx)):\n",
    "    full_data_crop.Description = full_data_crop.Description.str.replace(interests_rgx[i], interests_names[i])\n",
    "\n",
    "# remove un-needed rows based on Description column\n",
    "_filter = full_data_crop.Description.isin(interests_names)\n",
    "full_data_crop = full_data_crop[_filter]\n",
    "\n",
    "# unstack data\n",
    "full_data_crop.index = pd.MultiIndex.from_arrays([full_data_crop.Description.values, full_data_crop.Country.values, full_data_crop.Date.values])\n",
    "\n",
    "# We discovered that there are 3 duplicated lines in the file 2014-10-04 from liberia\n",
    "# We then had to delete the duplicated rows from the data so that we could unstack it\n",
    "full_data_crop = full_data_crop[~full_data_crop.index.duplicated(keep='first')]\n",
    "full_data_crop = full_data_crop.drop(['Description', 'Date', 'Country'], axis=1)\n",
    "\n",
    "# unstack the Descriptions and remove unneccessary index level\n",
    "full_data_crop = full_data_crop.unstack(level=0)\n",
    "full_data_crop.columns = full_data_crop.columns.droplevel()\n",
    "\n",
    "# convert fields to numeric values\n",
    "full_data_crop = full_data_crop.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the data looks like at this point. We have a single dataframe, containing the 3 countries' data, from which we can compute the daily averages per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_data_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Daily averages computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined two functions that, given the country name and names of columns we are interested in, return the daily average number of new cases (resp. deaths) per month in that country.\n",
    "\n",
    "Since we have no further information about the meanings of *probable*, *suspected* and *confirmed*, we chose not to aggregate those values and compute a daily average for each of them.\n",
    "\n",
    "Since we assumed deaths to be cumulative (see *Assumptions*), we had to find a different way to compute the average deaths. In order to do so, for each report we compute the difference between its *deaths* value and the *deaths* value of the preceding report. Then we compute the daily average per month from this difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns a df containing the mean number of new cases for the country given in argument, \n",
    "# respectively for confirmed, probable and suspected new cases\n",
    "def compute_new_cases(country, col_names):\n",
    "    # take only the data for the country given in argument, and group the values by month\n",
    "    country_data = full_data_crop[full_data_crop.Country == country]\n",
    "    country_data = country_data.groupby(country_data.Date.dt.month)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for name in col_names:\n",
    "        df[name] = country_data[name].mean()\n",
    "    df['Country'] = country\n",
    "    df = df.set_index(['Country'], append=True)\n",
    "    df = df.swaplevel(0, 1)\n",
    "    return df\n",
    "\n",
    "# Same thing as the previous function, but for the number of deaths\n",
    "def compute_deaths(country, col_names):\n",
    "    # take only the data for the country given in argument, and group the values by month\n",
    "    country_data = full_data_crop[full_data_crop.Country == country]\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for name in col_names:\n",
    "        death_values = country_data[name].subtract(country_data[name].shift(1))\n",
    "        country_data[name] = death_values\n",
    "    \n",
    "    country_data = country_data.groupby(country_data.Date.dt.month)\n",
    "    \n",
    "    for name in col_names:\n",
    "        df[name] = country_data[name].mean()\n",
    "        #df[name] = (np.max(country_data[name]) - np.min(country_data[name])).divide((np.max(country_data['Date']) - np.min(country_data['Date'])).dt.days)\n",
    "    df['Country'] = country\n",
    "    df = df.set_index(['Country'], append=True)\n",
    "    df = df.swaplevel(0, 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# put Date and Country back as columns (from the indexes) to make groupbys cleaner\n",
    "full_data_crop['Date'] = full_data_crop.index.get_level_values(1).values\n",
    "full_data_crop['Country'] = full_data_crop.index.get_level_values(0).values\n",
    "\n",
    "guinea_new_cases = compute_new_cases('Guinea', interests_new_cases)\n",
    "guinea_deaths = compute_deaths('Guinea', interests_death)\n",
    "\n",
    "liberia_new_cases = compute_new_cases('Liberia', interests_new_cases)\n",
    "liberia_deaths = compute_deaths('Liberia', interests_death)\n",
    "\n",
    "sl_new_cases = compute_new_cases('Sierra Leone', interests_new_cases)\n",
    "sl_deaths = compute_deaths('Sierra Leone', interests_death)\n",
    "\n",
    "new_cases_daily_means = pd.concat([guinea_new_cases, liberia_new_cases, sl_new_cases])\n",
    "new_cases_daily_means['Total new cases'] = new_cases_daily_means.sum(axis=1)\n",
    "deaths_daily_means = pd.concat([guinea_deaths, liberia_deaths, sl_deaths])\n",
    "deaths_daily_means['Total deaths'] = deaths_daily_means.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the daily average per month of new cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths_daily_means.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the daily average per month of deaths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deaths_daily_means.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN values\n",
    "There are NaN values at some places in the results. This happens when there is not a single data sample for an entire month. We decided to leave these NaN values as is, as we don't have enough data to interpolate missing values. We just replaced the NaNs by \"-\" to make it clear that there is no data here.\n",
    "\n",
    "#### Outliers\n",
    "The only big outlier values we have are for Liberia (new cases) during the month of december. We suspect that at some point during the month, the reports became cumulative for some reason. Since we have no way to confirm it, we decided to leave these values as they are, although we could have processed them as cumulative values (as we did it for deaths).\n",
    "\n",
    "#### Cumulative values decreasing\n",
    "Sometimes, even though the values are cumulative, we noticed that some values can decrease over time. After some research on the internet, we found that it could be because of some mistakes that were corrected (people we thought were dead but actually no)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. RNA Sequences\n",
    "\n",
    "In the `DATA_FOLDER/microbiome` subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10<sup>th</sup> file that describes the content of each. \n",
    "\n",
    "Use pandas to import the first 9 spreadsheets into a single `DataFrame`.\n",
    "Then, add the metadata information from the 10<sup>th</sup> spreadsheet as columns in the combined `DataFrame`.\n",
    "Make sure that the final `DataFrame` has a unique index and all the `NaN` values have been replaced by the tag `unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "path = DATA_FOLDER + \"/microbiome/\"\n",
    "for file in os.listdir(path):\n",
    "    if file != 'metadata.xls' :\n",
    "        dfs.append(pd.read_excel(path + '/' + file , header = None , index_col = 0))\n",
    "    \n",
    "Meta = pd.read_excel(\"Data/microbiome/metadata.xls\", index_col = 0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta['SAMPLE'].fillna('unknown' , inplace = True )\n",
    "arrays = [Meta['GROUP'].values, Meta['SAMPLE'].values]\n",
    "arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge = pd.concat(dfs , axis = 1)\n",
    "merge.columns = arrays\n",
    "merge.fillna('unknown' , inplace = True )\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merge.shape)\n",
    "merge.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Class War in Titanic\n",
    "\n",
    "Use pandas to import the data file `Data/titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob, os  \n",
    "\n",
    "df3 = pd.read_excel(DATA_FOLDER+'/titanic.xls')\n",
    "HTML(filename=DATA_FOLDER+'/titanic.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the following questions state clearly your assumptions and discuss your findings:\n",
    "1. Describe the *type* and the *value range* of each attribute. Indicate and transform the attributes that can be `Categorical`. \n",
    "2. Plot histograms for the *travel class*, *embarkation port*, *sex* and *age* attributes. For the latter one, use *discrete decade intervals*. \n",
    "3. Calculate the proportion of passengers by *cabin floor*. Present your results in a *pie chart*.\n",
    "4. For each *travel class*, calculate the proportion of the passengers that survived. Present your results in *pie charts*.\n",
    "5. Calculate the proportion of the passengers that survived by *travel class* and *sex*. Present your results in *a single histogram*.\n",
    "6. Create 2 equally populated *age categories* and calculate survival proportions by *age category*, *travel class* and *sex*. Present your results in a `DataFrame` with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Describing the type of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information about the attributes of our dataset, we will set to caterogical (sex,cabin,embarked,boat and home.dest) features to categorical. Body, ticket and name normally being different for all passengers are not converted to categorical. \n",
    "\n",
    "There are 295 cabins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(df3.groupby('name').count()))\n",
    "df3.groupby('name').count()\n",
    "a = df3.index[df3.name.isnull() == True]\n",
    "df3.loc[a]\n",
    "print((df3.name.value_counts()>1)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that there are two people without names. when trying to see their attributes we see no rows. Maybe some people have their name written twice. Those people are Kelly, Mr. James and Connolly, Miss. Kate. Looking at their attributes, we will remove the versions with the least amount of data, loc[726,925]. We could also have decided to keep the four rows or to delete two of them in function of the fare they paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[df3.name.isin(['Connolly, Miss. Kate','Kelly, Mr. James'])]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
<<<<<<< Updated upstream
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Anderson, Mr. Harry</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19952</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>E12</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Miss. Kornelia Theodosia</td>\n",
       "      <td>female</td>\n",
       "      <td>63.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>D7</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hudson, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast, NI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Appleton, Mrs. Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>female</td>\n",
       "      <td>53.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>C101</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bayside, Queens, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Artagaveytia, Mr. Ramon</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17609</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Montevideo, Uruguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Astor, Col. John Jacob</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>C62 C64</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124.0</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Astor, Mrs. John Jacob (Madeleine Talmadge Force)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>C62 C64</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Aubart, Mme. Leontine Pauline</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17477</td>\n",
       "      <td>69.3000</td>\n",
       "      <td>B35</td>\n",
       "      <td>C</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris, France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Barber, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19877</td>\n",
       "      <td>78.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Barkworth, Mr. Algernon Henry Wilson</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27042</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>A23</td>\n",
       "      <td>S</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hessle, Yorks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Baumann, Mr. John D</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17318</td>\n",
       "      <td>25.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Baxter, Mr. Quigg Edmond</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17558</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>B58 B60</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Baxter, Mrs. James (Helene DeLaudeniere Chaput)</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17558</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>B58 B60</td>\n",
       "      <td>C</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bazzani, Miss. Albina</td>\n",
       "      <td>female</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11813</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>D15</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Beattie, Mr. Thomson</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13050</td>\n",
       "      <td>75.2417</td>\n",
       "      <td>C6</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winnipeg, MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mr. Richard Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>37.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bidois, Miss. Rosalie</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bird, Miss. Ellen</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17483</td>\n",
       "      <td>221.7792</td>\n",
       "      <td>C97</td>\n",
       "      <td>S</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Birnbaum, Mr. Jakob</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13905</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bishop, Mr. Dickinson H</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11967</td>\n",
       "      <td>91.0792</td>\n",
       "      <td>B49</td>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dowagiac, MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bishop, Mrs. Dickinson H (Helen Walton)</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11967</td>\n",
       "      <td>91.0792</td>\n",
       "      <td>B49</td>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dowagiac, MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bissette, Miss. Amelia</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17760</td>\n",
       "      <td>135.6333</td>\n",
       "      <td>C99</td>\n",
       "      <td>S</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bjornstrom-Steffansson, Mr. Mauritz Hakan</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110564</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C52</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stockholm, Sweden / Washington, DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Vovk, Mr. Janko</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349252</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Waelens, Mr. Achille</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345767</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antwerp, Belgium / Stanton, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Warren, Mr. Charles William</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 49867</td>\n",
       "      <td>7.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Webber, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 3101316</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Wenzel, Mr. Linhart</td>\n",
       "      <td>male</td>\n",
       "      <td>32.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345775</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Whabee, Mrs. George Joseph (Shawneene Abi-Saab)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2688</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Widegren, Mr. Carl/Charles Peter</td>\n",
       "      <td>male</td>\n",
       "      <td>51.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347064</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Wiklund, Mr. Jakob Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3101267</td>\n",
       "      <td>6.4958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Wiklund, Mr. Karl Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3101266</td>\n",
       "      <td>6.4958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Willer, Mr. Aaron (\"Abi Weller\")</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3410</td>\n",
       "      <td>8.7125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Willey, Mr. Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O./P.P. 751</td>\n",
       "      <td>7.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Williams, Mr. Howard Hugh \"Harry\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 2466</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Williams, Mr. Leslie</td>\n",
       "      <td>male</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54636</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Windelov, Mr. Einar</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 3101317</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Wiseman, Mr. Phillippe</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/4. 34244</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Wittevrongel, Mr. Camille</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345771</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Yasbeck, Mr. Antoni</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2659</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Yasbeck, Mrs. Antoni (Selini Alexander)</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2659</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Youseff, Mr. Gerious</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2628</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>312.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Yousif, Mr. Wazli</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2647</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Yousseff, Mr. Gerious</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2627</td>\n",
       "      <td>14.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zabour, Miss. Hileni</td>\n",
       "      <td>female</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zabour, Miss. Thamine</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr. Mapriededer</td>\n",
       "      <td>male</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2656</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zakarian, Mr. Ortin</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2670</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Zimmerman, Mr. Leo</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315082</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1307 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  survived                                               name  \\\n",
       "0          1         1                      Allen, Miss. Elisabeth Walton   \n",
       "1          1         1                     Allison, Master. Hudson Trevor   \n",
       "2          1         0                       Allison, Miss. Helen Loraine   \n",
       "3          1         0               Allison, Mr. Hudson Joshua Creighton   \n",
       "4          1         0    Allison, Mrs. Hudson J C (Bessie Waldo Daniels)   \n",
       "5          1         1                                Anderson, Mr. Harry   \n",
       "6          1         1                  Andrews, Miss. Kornelia Theodosia   \n",
       "7          1         0                             Andrews, Mr. Thomas Jr   \n",
       "8          1         1      Appleton, Mrs. Edward Dale (Charlotte Lamson)   \n",
       "9          1         0                            Artagaveytia, Mr. Ramon   \n",
       "10         1         0                             Astor, Col. John Jacob   \n",
       "11         1         1  Astor, Mrs. John Jacob (Madeleine Talmadge Force)   \n",
       "12         1         1                      Aubart, Mme. Leontine Pauline   \n",
       "13         1         1                       Barber, Miss. Ellen \"Nellie\"   \n",
       "14         1         1               Barkworth, Mr. Algernon Henry Wilson   \n",
       "15         1         0                                Baumann, Mr. John D   \n",
       "16         1         0                           Baxter, Mr. Quigg Edmond   \n",
       "17         1         1    Baxter, Mrs. James (Helene DeLaudeniere Chaput)   \n",
       "18         1         1                              Bazzani, Miss. Albina   \n",
       "19         1         0                               Beattie, Mr. Thomson   \n",
       "20         1         1                      Beckwith, Mr. Richard Leonard   \n",
       "21         1         1   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)   \n",
       "22         1         1                              Behr, Mr. Karl Howell   \n",
       "23         1         1                              Bidois, Miss. Rosalie   \n",
       "24         1         1                                  Bird, Miss. Ellen   \n",
       "25         1         0                                Birnbaum, Mr. Jakob   \n",
       "26         1         1                            Bishop, Mr. Dickinson H   \n",
       "27         1         1            Bishop, Mrs. Dickinson H (Helen Walton)   \n",
       "28         1         1                             Bissette, Miss. Amelia   \n",
       "29         1         1          Bjornstrom-Steffansson, Mr. Mauritz Hakan   \n",
       "...      ...       ...                                                ...   \n",
       "1279       3         0               Vestrom, Miss. Hulda Amanda Adolfina   \n",
       "1280       3         0                                    Vovk, Mr. Janko   \n",
       "1281       3         0                               Waelens, Mr. Achille   \n",
       "1282       3         0                                Ware, Mr. Frederick   \n",
       "1283       3         0                        Warren, Mr. Charles William   \n",
       "1284       3         0                                  Webber, Mr. James   \n",
       "1285       3         0                                Wenzel, Mr. Linhart   \n",
       "1286       3         1    Whabee, Mrs. George Joseph (Shawneene Abi-Saab)   \n",
       "1287       3         0                   Widegren, Mr. Carl/Charles Peter   \n",
       "1288       3         0                          Wiklund, Mr. Jakob Alfred   \n",
       "1289       3         0                            Wiklund, Mr. Karl Johan   \n",
       "1290       3         1                   Wilkes, Mrs. James (Ellen Needs)   \n",
       "1291       3         0                   Willer, Mr. Aaron (\"Abi Weller\")   \n",
       "1292       3         0                                 Willey, Mr. Edward   \n",
       "1293       3         0                  Williams, Mr. Howard Hugh \"Harry\"   \n",
       "1294       3         0                               Williams, Mr. Leslie   \n",
       "1295       3         0                                Windelov, Mr. Einar   \n",
       "1296       3         0                                   Wirz, Mr. Albert   \n",
       "1297       3         0                             Wiseman, Mr. Phillippe   \n",
       "1298       3         0                          Wittevrongel, Mr. Camille   \n",
       "1299       3         0                                Yasbeck, Mr. Antoni   \n",
       "1300       3         1            Yasbeck, Mrs. Antoni (Selini Alexander)   \n",
       "1301       3         0                               Youseff, Mr. Gerious   \n",
       "1302       3         0                                  Yousif, Mr. Wazli   \n",
       "1303       3         0                              Yousseff, Mr. Gerious   \n",
       "1304       3         0                               Zabour, Miss. Hileni   \n",
       "1305       3         0                              Zabour, Miss. Thamine   \n",
       "1306       3         0                          Zakarian, Mr. Mapriededer   \n",
       "1307       3         0                                Zakarian, Mr. Ortin   \n",
       "1308       3         0                                 Zimmerman, Mr. Leo   \n",
       "\n",
       "         sex      age  sibsp  parch            ticket      fare    cabin  \\\n",
       "0     female  29.0000      0      0             24160  211.3375       B5   \n",
       "1       male   0.9167      1      2            113781  151.5500  C22 C26   \n",
       "2     female   2.0000      1      2            113781  151.5500  C22 C26   \n",
       "3       male  30.0000      1      2            113781  151.5500  C22 C26   \n",
       "4     female  25.0000      1      2            113781  151.5500  C22 C26   \n",
       "5       male  48.0000      0      0             19952   26.5500      E12   \n",
       "6     female  63.0000      1      0             13502   77.9583       D7   \n",
       "7       male  39.0000      0      0            112050    0.0000      A36   \n",
       "8     female  53.0000      2      0             11769   51.4792     C101   \n",
       "9       male  71.0000      0      0          PC 17609   49.5042      NaN   \n",
       "10      male  47.0000      1      0          PC 17757  227.5250  C62 C64   \n",
       "11    female  18.0000      1      0          PC 17757  227.5250  C62 C64   \n",
       "12    female  24.0000      0      0          PC 17477   69.3000      B35   \n",
       "13    female  26.0000      0      0             19877   78.8500      NaN   \n",
       "14      male  80.0000      0      0             27042   30.0000      A23   \n",
       "15      male      NaN      0      0          PC 17318   25.9250      NaN   \n",
       "16      male  24.0000      0      1          PC 17558  247.5208  B58 B60   \n",
       "17    female  50.0000      0      1          PC 17558  247.5208  B58 B60   \n",
       "18    female  32.0000      0      0             11813   76.2917      D15   \n",
       "19      male  36.0000      0      0             13050   75.2417       C6   \n",
       "20      male  37.0000      1      1             11751   52.5542      D35   \n",
       "21    female  47.0000      1      1             11751   52.5542      D35   \n",
       "22      male  26.0000      0      0            111369   30.0000     C148   \n",
       "23    female  42.0000      0      0          PC 17757  227.5250      NaN   \n",
       "24    female  29.0000      0      0          PC 17483  221.7792      C97   \n",
       "25      male  25.0000      0      0             13905   26.0000      NaN   \n",
       "26      male  25.0000      1      0             11967   91.0792      B49   \n",
       "27    female  19.0000      1      0             11967   91.0792      B49   \n",
       "28    female  35.0000      0      0          PC 17760  135.6333      C99   \n",
       "29      male  28.0000      0      0            110564   26.5500      C52   \n",
       "...      ...      ...    ...    ...               ...       ...      ...   \n",
       "1279  female  14.0000      0      0            350406    7.8542      NaN   \n",
       "1280    male  22.0000      0      0            349252    7.8958      NaN   \n",
       "1281    male  22.0000      0      0            345767    9.0000      NaN   \n",
       "1282    male      NaN      0      0            359309    8.0500      NaN   \n",
       "1283    male      NaN      0      0        C.A. 49867    7.5500      NaN   \n",
       "1284    male      NaN      0      0  SOTON/OQ 3101316    8.0500      NaN   \n",
       "1285    male  32.5000      0      0            345775    9.5000      NaN   \n",
       "1286  female  38.0000      0      0              2688    7.2292      NaN   \n",
       "1287    male  51.0000      0      0            347064    7.7500      NaN   \n",
       "1288    male  18.0000      1      0           3101267    6.4958      NaN   \n",
       "1289    male  21.0000      1      0           3101266    6.4958      NaN   \n",
       "1290  female  47.0000      1      0            363272    7.0000      NaN   \n",
       "1291    male      NaN      0      0              3410    8.7125      NaN   \n",
       "1292    male      NaN      0      0     S.O./P.P. 751    7.5500      NaN   \n",
       "1293    male      NaN      0      0          A/5 2466    8.0500      NaN   \n",
       "1294    male  28.5000      0      0             54636   16.1000      NaN   \n",
       "1295    male  21.0000      0      0  SOTON/OQ 3101317    7.2500      NaN   \n",
       "1296    male  27.0000      0      0            315154    8.6625      NaN   \n",
       "1297    male      NaN      0      0        A/4. 34244    7.2500      NaN   \n",
       "1298    male  36.0000      0      0            345771    9.5000      NaN   \n",
       "1299    male  27.0000      1      0              2659   14.4542      NaN   \n",
       "1300  female  15.0000      1      0              2659   14.4542      NaN   \n",
       "1301    male  45.5000      0      0              2628    7.2250      NaN   \n",
       "1302    male      NaN      0      0              2647    7.2250      NaN   \n",
       "1303    male      NaN      0      0              2627   14.4583      NaN   \n",
       "1304  female  14.5000      1      0              2665   14.4542      NaN   \n",
       "1305  female      NaN      1      0              2665   14.4542      NaN   \n",
       "1306    male  26.5000      0      0              2656    7.2250      NaN   \n",
       "1307    male  27.0000      0      0              2670    7.2250      NaN   \n",
       "1308    male  29.0000      0      0            315082    7.8750      NaN   \n",
       "\n",
       "     embarked boat   body                           home.dest  \n",
       "0           S    2    NaN                        St Louis, MO  \n",
       "1           S   11    NaN     Montreal, PQ / Chesterville, ON  \n",
       "2           S  NaN    NaN     Montreal, PQ / Chesterville, ON  \n",
       "3           S  NaN  135.0     Montreal, PQ / Chesterville, ON  \n",
       "4           S  NaN    NaN     Montreal, PQ / Chesterville, ON  \n",
       "5           S    3    NaN                        New York, NY  \n",
       "6           S   10    NaN                          Hudson, NY  \n",
       "7           S  NaN    NaN                         Belfast, NI  \n",
       "8           S    D    NaN                 Bayside, Queens, NY  \n",
       "9           C  NaN   22.0                 Montevideo, Uruguay  \n",
       "10          C  NaN  124.0                        New York, NY  \n",
       "11          C    4    NaN                        New York, NY  \n",
       "12          C    9    NaN                       Paris, France  \n",
       "13          S    6    NaN                                 NaN  \n",
       "14          S    B    NaN                       Hessle, Yorks  \n",
       "15          S  NaN    NaN                        New York, NY  \n",
       "16          C  NaN    NaN                        Montreal, PQ  \n",
       "17          C    6    NaN                        Montreal, PQ  \n",
       "18          C    8    NaN                                 NaN  \n",
       "19          C    A    NaN                        Winnipeg, MN  \n",
       "20          S    5    NaN                        New York, NY  \n",
       "21          S    5    NaN                        New York, NY  \n",
       "22          C    5    NaN                        New York, NY  \n",
       "23          C    4    NaN                                 NaN  \n",
       "24          S    8    NaN                                 NaN  \n",
       "25          C  NaN  148.0                   San Francisco, CA  \n",
       "26          C    7    NaN                        Dowagiac, MI  \n",
       "27          C    7    NaN                        Dowagiac, MI  \n",
       "28          S    8    NaN                                 NaN  \n",
       "29          S    D    NaN  Stockholm, Sweden / Washington, DC  \n",
       "...       ...  ...    ...                                 ...  \n",
       "1279        S  NaN    NaN                                 NaN  \n",
       "1280        S  NaN    NaN                                 NaN  \n",
       "1281        S  NaN    NaN      Antwerp, Belgium / Stanton, OH  \n",
       "1282        S  NaN    NaN                                 NaN  \n",
       "1283        S  NaN    NaN                                 NaN  \n",
       "1284        S  NaN    NaN                                 NaN  \n",
       "1285        S  NaN  298.0                                 NaN  \n",
       "1286        C    C    NaN                                 NaN  \n",
       "1287        S  NaN    NaN                                 NaN  \n",
       "1288        S  NaN  314.0                                 NaN  \n",
       "1289        S  NaN    NaN                                 NaN  \n",
       "1290        S  NaN    NaN                                 NaN  \n",
       "1291        S  NaN    NaN                                 NaN  \n",
       "1292        S  NaN    NaN                                 NaN  \n",
       "1293        S  NaN    NaN                                 NaN  \n",
       "1294        S  NaN   14.0                                 NaN  \n",
       "1295        S  NaN    NaN                                 NaN  \n",
       "1296        S  NaN  131.0                                 NaN  \n",
       "1297        S  NaN    NaN                                 NaN  \n",
       "1298        S  NaN    NaN                                 NaN  \n",
       "1299        C    C    NaN                                 NaN  \n",
       "1300        C  NaN    NaN                                 NaN  \n",
       "1301        C  NaN  312.0                                 NaN  \n",
       "1302        C  NaN    NaN                                 NaN  \n",
       "1303        C  NaN    NaN                                 NaN  \n",
       "1304        C  NaN  328.0                                 NaN  \n",
       "1305        C  NaN    NaN                                 NaN  \n",
       "1306        C  NaN  304.0                                 NaN  \n",
       "1307        C  NaN    NaN                                 NaN  \n",
       "1308        S  NaN    NaN                                 NaN  \n",
       "\n",
       "[1307 rows x 14 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
>>>>>>> Stashed changes
   "source": [
    "df3 = df3.drop(df3.index[[726,925]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert to categorical\n",
    "df3[\"sex\"] = pd.Categorical(df3['sex'], df3['sex'].unique())\n",
    "df3['cabin'] = df3['cabin'].fillna('missing')\n",
    "df3[\"cabin\"] = pd.Categorical(df3['cabin'], df3['cabin'].unique())\n",
    "df3['embarked'] = df3['embarked'].fillna('missing')\n",
    "df3[\"embarked\"] = pd.Categorical(df3['embarked'], df3['embarked'].unique())\n",
    "df3['boat'] = df3['boat'].fillna('missing')\n",
    "df3[\"boat\"] = pd.Categorical(df3['boat'], df3['boat'].unique())\n",
    "df3['home.dest'] = df3['home.dest'].fillna('missing')\n",
    "df3[\"home.dest\"] = pd.Categorical(df3['home.dest'], df3['home.dest'].unique())\n",
    "\n",
    "df3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "df3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "talk about range and type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now all the missing values have been cleaned except for the body column. Since there are only 121 entries out of 1309, we will see later if we remove this column.\n",
    "\n",
    "### 2. Plot histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "fig.set_size_inches(20,20)\n",
    "\n",
    "df_temporary = df3.copy()\n",
    "df_temporary.age = pd.cut(df3.age, [0,10,20,30,40,50,60,70,80,90])\n",
    "sns.countplot(x='age',data=df_temporary,ax=axes[0,0])\n",
    "axes[0,0].set_xlabel('age')\n",
    "axes[0,0].set_ylabel('count')\n",
    "\n",
    "classes = df3.groupby('pclass').size()\n",
    "#df3.hist('pclass',ax=axes[0,1])\n",
    "classes.plot(kind='bar',ax=axes[0,1])\n",
    "axes[0,1].set_xlabel('class')\n",
    "axes[0,1].set_ylabel('count')\n",
    "\n",
    "sns.countplot(x='sex',data=df3,ax=axes[1,0])\n",
    "\n",
    "sns.countplot(x='embarked',data=df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram observations\n",
    "- We can observe the passenger age distribution in the titanic is gaussian\n",
    "- There is a higher amount of males onboard\n",
    "- There were more people embarked in third class then first and second combined\n",
    "- Most of the passengers boarded in Southampton\n",
    "\n",
    "### 3. Calculate the proportion of passengers by cabin floor\n",
    "We make the assumption that for cabins with name as 'F E69' belong to the cabin floor F. It should be noted that the following pie chart does not represent perfectly the true proportion of passengers per cabin floor as only 295 out of 1309 values of the cabin column are filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3['cabin_floor'] = df3.cabin.apply(lambda x: x[0])\n",
    "df3.cabin_floor = df3.cabin_floor[df3.cabin_floor != 'm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as ip\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "#from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "\n",
    "#ip.tools.set_credentials_file(username='USERNAME', api_key='KEY')\n",
    "#trace = go.Pie(labels=df3['cabin_floor'].value_counts().index, values=df3['cabin_floor'].value_counts())\n",
    "#py.iplot([trace], filename='Proportion of passengers per cabin floor')\n",
    "\n",
    "\n",
    "from IPython.display import IFrame\n",
    "IFrame('https://plot.ly/~mgelsm/2', width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image is plotted in case the viewer does not run the boxes. The interactive plot is however not available below.\n",
    "<div>\n",
    "    <a href=\"https://plot.ly/~mgelsm/2/?share_key=LTW3TPD50iXkdYukf55G9j\" target=\"_blank\" title=\"Proportion of passengers per cabin floor\" style=\"display: block; text-align: center;\"><img src=\"https://plot.ly/~mgelsm/2.png?share_key=LTW3TPD50iXkdYukf55G9j\" alt=\"Proportion of passengers per cabin floor\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n",
    "    <script data-plotly=\"mgelsm:2\" sharekey-plotly=\"LTW3TPD50iXkdYukf55G9j\" src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. For each travel class, calculate the proportion of the passengers that survived. Present your results in pie charts."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgelsm/38.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Pie(labels=df3.loc[df3.pclass == 1].survived.value_counts().index, values=df3.loc[df3.pclass == 1].survived.value_counts())\n",
    "py.iplot([trace], filename='Proportion of passengers per cabin floor in first class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgelsm/40.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Pie(labels=df3.loc[df3.pclass == 2].survived.value_counts().index, values=df3.loc[df3.pclass == 2].survived.value_counts())\n",
    "py.iplot([trace], filename='Proportion of passengers per cabin floor in second class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgelsm/40.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Pie(labels=df3.loc[df3.pclass == 3].survived.value_counts().index, values=df3.loc[df3.pclass == 3].survived.value_counts())\n",
    "py.iplot([trace], filename='Proportion of passengers per cabin floor in second class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~mgelsm/42.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> Stashed changes
   "source": [
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "fig = {\n",
    "    'data': [\n",
    "        {\n",
    "              \"labelssrc\": \"mgelsm:37:6e0852\",\n",
    "              \"uid\": \"69a511\",\n",
    "              'name': 'first class',\n",
    "              \"labels\": [\n",
    "                \"died\",\n",
    "                \"survived\"\n",
    "              ],\n",
    "              \"values\": [\n",
    "                158,\n",
    "                119\n",
    "              ],\n",
    "              \"type\": \"pie\",\n",
    "             'domain': {'x': [0, .3],\n",
    "                       'y': [0, 1]},\n",
    "              \"valuessrc\": \"mgelsm:37:346a41\",\n",
    "              'hoverinfo':'label+percent+name',\n",
    "              'textinfo':'name'\n",
    "        },\n",
    "        {\n",
    "              \"labelssrc\": \"mgelsm:39:868d87\",\n",
    "              \"uid\": \"dd4ae4\",\n",
    "              \"name\": \"Second class\",\n",
    "              \"labels\": [\n",
    "                \"survived\",\n",
    "                \"died\"\n",
    "              ],\n",
    "              \"values\": [\n",
    "                200,\n",
    "                123\n",
    "              ],\n",
    "              \"type\": \"pie\",\n",
    "              'domain': {'x': [.35, 0.65],\n",
    "                       'y': [0, 1]},\n",
    "              \"valuessrc\": \"mgelsm:39:e4a7d4\",\n",
    "              'hoverinfo':'label+percent+name'\n",
    "              \n",
    "        },\n",
    "        {\n",
    "          \"labelssrc\": \"mgelsm:41:d33c0d\",\n",
    "          \"uid\": \"ed234e\",\n",
    "          \"labels\": [\n",
    "            \"died\",\n",
    "            \"survived\"\n",
    "          ],\n",
    "          \"values\": [\n",
    "            526,\n",
    "            181\n",
    "          ],\n",
    "          \"type\": \"pie\",\n",
    "          'domain': {'x': [.7, 1],\n",
    "                       'y': [0, 1]},\n",
    "          \"valuessrc\": \"mgelsm:41:ee72c5\",\n",
    "          'hoverinfo':'label+percent+name',\n",
    "          \"name\": \"3rd class\"  \n",
    "        }\n",
    "        ],\n",
    "    'layout': {'title': 'Survival rates per class',\n",
    "               'showlegend': True}\n",
    "    }\n",
    "\n",
    "py.iplot(fig, filename='pie_chart_subplots')\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the web plot is given here in case the notebook isn't ran by the reader.\n",
    "<div>\n",
    "    <a href=\"https://plot.ly/~mgelsm/42/?share_key=jeDi58oBAX9ggAAVNN5Lfx\" target=\"_blank\" title=\"pie_chart_subplots\" style=\"display: block; text-align: center;\"><img src=\"https://plot.ly/~mgelsm/42.png?share_key=jeDi58oBAX9ggAAVNN5Lfx\" alt=\"pie_chart_subplots\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n",
    "    <script data-plotly=\"mgelsm:42\" sharekey-plotly=\"jeDi58oBAX9ggAAVNN5Lfx\" src=\"https://plot.ly/embed.js\" async></script>\n",
    "</div>\n",
    "\n",
    "\n",
    "### 5. Calculate the proportion of the passengers that survived by travel class and sex. Present your results in a single histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.barplot(x='sex',y='survived',hue='pclass',data=df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that more women survived from the titanic sinking and upper classes have a higher rate of survival.\n",
    "\n",
    "### 6. Create 2 equally populated age categories and calculate survival proportions by age category, travel class and sex. Present your results in a DataFrame with unique index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['age_class'] = df3.age < df3.age.median()\n",
    "df3.age.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_category(x):\n",
    "    if x.age_class == False and x.sex == 'female':\n",
    "        val = 'young_female'\n",
    "    elif x.age_class == True and x.sex == 'female':\n",
    "        val = 'old_female'\n",
    "    elif x.age_class == False and x.sex == 'male':\n",
    "        val = 'young_male'\n",
    "    else:\n",
    "        val = 'old_male'   \n",
    "    return val\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3['age_sex'] = df3.apply(create_category,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='age_sex',y='survived',hue='pclass',data=df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This histogram shows two important things :\n",
    "1. There is a higher rate of Women and children that survived\n",
    "2. People in hihger classes had better chances of surviving\n",
    "\n",
    "Hence we can understand that the rule of saving children and women first was applied during the titanic sinking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
